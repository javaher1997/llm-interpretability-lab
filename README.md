# llm-interpretability-lab
Research-oriented analysis of Transformer-based language models, focusing on internal representations, attention mechanisms, reasoning behavior, and failure modes.
